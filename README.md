## ğŸ§  Retrieval-Augmented QA Pipeline (RAG) 
## Using FAISS + Azure OpenAI

This project implements a fully local **RAG system** that:
- Extracts structured chunks from `.docx` documents
- Indexes them using FAISS Vector Database
- Re-ranks results using a cross-encoder
- Generates answers using Azure OpenAI (GPT-35-Turbo)
- Supports a Gradio UI for interactive querying

---

## ğŸš€ Setup Instructions

### âœ… Step 1: Set Up Python Environment (Python 3.12.3)

a. Create and activate a virtual environment:
python -m venv venv

b. Activate the venv:
source venv/bin/activate  # Or venv\\Scripts\\activate on Windows

c. allow local script execution:
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass

d. Then activate again:
source venv/bin/activate  # Or venv\\Scripts\\activate on Windows

### âœ… Step 2: Install PyTorch (CPU version)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

### âœ… Step 3: Install Other Dependencies
pip install -r requirements.txt

### ğŸ§© Project Structure
.
â”œâ”€â”€ faiss_client.py        # Handles .docx parsing, chunking, and FAISS indexing
â”œâ”€â”€ qa_pipeline.py         # Full RAG pipeline: retrieval, reranking, prompt, and LLM answer
â”œâ”€â”€ gradio_app.py          # Gradio interface for querying the system
â”œâ”€â”€ word_files/            # Folder with your input Word documents (*.docx)
â”œâ”€â”€ faiss_index.index      # Saved FAISS vector index (auto-generated)
â”œâ”€â”€ faiss_metadata.json    # Metadata for each indexed chunk (auto-generated)
â””â”€â”€ requirements.txt



## ğŸ› ï¸ Running the System

### ğŸ”¹ 1. Build the FAISS Index
#### Run the FAISS indexer to process your .docx files and save the index:
RUN: python faiss_client.py

This will:
Chunk all .docx files in ./word_files/
Create faiss_index.index and faiss_metadata.json

### ğŸ”¹ 3. Launch the Gradio UI
RUN: python gradio_app.py
